# AI Cost Optimizer Configuration
# Copy this file to .env and add your API keys

# =============================================================================
# PRIMARY PROVIDERS (Recommended)
# =============================================================================

# Google Gemini - FREE tier available, great for simple queries
# Get key at: https://aistudio.google.com/app/apikey
# Pricing: $0.075 per 1M input tokens, $0.30 per 1M output tokens
GOOGLE_API_KEY=

# Anthropic Claude - Best quality for complex queries
# Get key at: https://console.anthropic.com/
# Pricing: Haiku $0.25/$1.25, Sonnet $3/$15, Opus $15/$75 per 1M tokens
ANTHROPIC_API_KEY=

# =============================================================================
# ULTRA-FAST PROVIDERS (Cerebras, Cartesia)
# =============================================================================

# Cerebras - FASTEST inference (1000+ tokens/sec), cheap Llama models
# Get key at: https://cloud.cerebras.ai/
# Pricing: ~$0.10 per 1M tokens for Llama 3.1 70B
CEREBRAS_API_KEY=

# Cartesia - Ultra-fast streaming, voice + text
# Get key at: https://cartesia.ai/
# Pricing: Varies by model
CARTESIA_API_KEY=

# =============================================================================
# LOCAL & SELF-HOSTED OPTIONS
# =============================================================================

# Ollama Cloud - Self-hosted models (when available)
# Note: Currently Ollama is primarily local. Set OLLAMA_BASE_URL for custom endpoint
# OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_API_KEY=

# RunPod - Deploy your own models on GPUs
# Get key at: https://www.runpod.io/console/user/settings
# Use for hosting custom models or endpoints
RUNPOD_API_KEY=

# =============================================================================
# AGGREGATORS & FALLBACKS
# =============================================================================

# OpenRouter - Access 40+ models through one API
# Get key at: https://openrouter.ai/keys
# Pricing: Varies by model, includes GPT-4, Claude, Gemini, Llama, etc.
OPENROUTER_API_KEY=

# =============================================================================
# OPTIONAL CONFIGURATION
# =============================================================================

# Database path (default: optimizer.db in project root)
DATABASE_PATH=optimizer.db

# Server port (default: 8000)
PORT=8000

# Log level: DEBUG, INFO, WARNING, ERROR (default: INFO)
LOG_LEVEL=INFO

# Custom endpoint URLs (if using self-hosted)
# OLLAMA_BASE_URL=http://localhost:11434
# RUNPOD_ENDPOINT_URL=https://your-endpoint.runpod.io
