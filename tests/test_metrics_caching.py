"""
Test suite for Redis caching integration with metrics endpoint (Task 4).

Tests follow TDD approach:
- RED: Write tests first (expect failures)
- GREEN: Implement features to pass tests
- REFACTOR: Optimize implementation

Goal: Reduce metrics query response from 50ms to <10ms using Redis caching.
"""

import pytest
import time
import json
from unittest.mock import Mock, patch, MagicMock
from fastapi.testclient import TestClient
from app.main import app
from app.cache import RedisCache


class TestMetricsCaching:
    """Test suite for Redis caching integration with /routing/metrics endpoint"""

    @pytest.fixture
    def client(self):
        """FastAPI test client"""
        return TestClient(app)

    @pytest.fixture
    def mock_redis_cache(self):
        """Mock RedisCache for testing"""
        mock = Mock(spec=RedisCache)
        mock.get.return_value = None  # Default to cache miss
        mock.set.return_value = True
        mock.delete.return_value = True
        return mock

    def test_metrics_endpoint_exists(self, client):
        """Test that metrics endpoint is accessible"""
        response = client.get("/routing/metrics")
        assert response.status_code == 200, "Metrics endpoint should exist and return 200"

    def test_metrics_response_structure(self, client):
        """Test that metrics response has expected structure"""
        response = client.get("/routing/metrics")
        assert response.status_code == 200
        data = response.json()

        # Verify it returns a dict (metrics from MetricsCollector)
        assert isinstance(data, dict), "Metrics should return a dictionary"

        # The structure should match MetricsCollector.get_metrics() output
        # which includes: strategy_performance, total_decisions, confidence_distribution, etc.
        assert "strategy_performance" in data or "total_decisions" in data or isinstance(data, dict)

    @patch('app.main.metrics_cache')
    def test_cache_hit_returns_cached_data(self, mock_cache, client):
        """Test that cache hit returns data from Redis without DB query"""
        cached_data = {
            "strategy_performance": {
                "hybrid": {"count": 10, "avg_cost": 0.05}
            },
            "total_decisions": 100,
            "confidence_distribution": {
                "high": 50,
                "medium": 30,
                "low": 20
            }
        }
        mock_cache.get.return_value = cached_data

        response = client.get("/routing/metrics")

        assert response.status_code == 200
        assert response.json() == cached_data
        mock_cache.get.assert_called_once_with("metrics:latest")

    @patch('app.main.metrics_cache')
    def test_cache_miss_queries_database_and_populates_cache(self, mock_cache, client):
        """Test that cache miss queries database and stores result in Redis with 30s TTL"""
        mock_cache.get.return_value = None  # Cache miss

        response = client.get("/routing/metrics")

        assert response.status_code == 200
        assert response.json() is not None

        # Verify cache was checked
        mock_cache.get.assert_called_once_with("metrics:latest")

        # Verify cache was populated with result
        mock_cache.set.assert_called_once()

        # Verify TTL is 30 seconds
        call_args = mock_cache.set.call_args
        assert call_args is not None
        # Check if ttl=30 was passed (could be positional or keyword arg)
        if len(call_args[0]) >= 3:
            # Positional: set(key, value, ttl)
            assert call_args[0][2] == 30 or call_args[1].get('ttl') == 30
        else:
            # Keyword: set(key, value, ttl=30)
            assert call_args[1].get('ttl') == 30

    @patch('app.main.metrics_cache')
    def test_redis_unavailable_fallback_to_database(self, mock_cache, client):
        """Test graceful fallback when Redis is unavailable"""
        # Simulate Redis failure
        mock_cache.get.side_effect = Exception("Redis connection failed")

        response = client.get("/routing/metrics")

        # Should still return data from database
        assert response.status_code == 200
        assert response.json() is not None

    @patch('app.main.metrics_cache')
    def test_cache_set_failure_graceful_degradation(self, mock_cache, client):
        """Test that cache SET failure doesn't break the endpoint"""
        mock_cache.get.return_value = None  # Cache miss
        mock_cache.set.side_effect = Exception("Redis SET failed")

        response = client.get("/routing/metrics")

        # Should still return data even if caching fails
        assert response.status_code == 200
        assert response.json() is not None

    def test_metrics_cached_response_performance(self, client):
        """Test that cached metrics response is under 10ms (performance requirement)"""
        # First request to populate cache (if caching is implemented)
        client.get("/routing/metrics")

        # Second request should hit cache (if caching is implemented)
        start = time.time()
        response = client.get("/routing/metrics")
        duration_ms = (time.time() - start) * 1000

        assert response.status_code == 200
        # This test will initially fail until caching is implemented
        # After implementation, cached requests should be <10ms
        # For now, we just measure and log (actual assertion happens after GREEN phase)
        print(f"Metrics response time: {duration_ms:.2f}ms")

    @patch('app.main.metrics_cache')
    def test_cache_invalidation_on_new_routing_decision(self, mock_cache, client):
        """Test that cache is invalidated when new routing decision is made"""
        # Mock the cache to track calls
        mock_cache.get.return_value = None
        mock_cache.delete.return_value = True

        # Make a completion request (which should invalidate metrics cache)
        # Note: This will fail if provider isn't available, so we'll just check
        # that the invalidation logic is called when implemented
        completion_data = {
            "prompt": "Test prompt for cache invalidation",
            "auto_route": True,
            "max_tokens": 100
        }

        try:
            response = client.post("/complete", json=completion_data)
            # If successful, verify cache was invalidated
            if response.status_code == 200:
                # Check that delete was called (implementation pending)
                pass  # Will be verified after implementation
        except Exception as e:
            # Provider might not be available in test environment
            # That's OK - we're testing the cache invalidation logic
            pass


class TestCacheStatistics:
    """Test suite for cache hit/miss statistics endpoint"""

    @pytest.fixture
    def client(self):
        """FastAPI test client"""
        return TestClient(app)

    def test_cache_stats_endpoint_exists(self, client):
        """Test that /cache/stats endpoint exists"""
        # Note: There's already a /cache/stats endpoint for response cache
        # We might add metrics-specific stats or extend existing endpoint
        response = client.get("/cache/stats")
        assert response.status_code == 200

    @patch('app.main.metrics_cache_stats')
    def test_cache_stats_structure(self, mock_stats, client):
        """Test cache stats response structure (after implementation)"""
        # This will test the metrics cache stats endpoint
        # Structure should include: hits, misses, hit_rate, total_requests, errors
        pass  # Will implement after stats tracking is added


class TestCacheKeyStrategy:
    """Test suite for cache key naming and organization"""

    @patch('app.main.metrics_cache')
    def test_cache_key_format(self, mock_cache, client):
        """Test that cache uses consistent key format"""
        mock_cache.get.return_value = None

        client.get("/routing/metrics")

        # Verify cache key is "metrics:latest"
        mock_cache.get.assert_called_once_with("metrics:latest")

    @patch('app.main.metrics_cache')
    def test_multiple_cache_keys_for_different_endpoints(self, mock_cache, client):
        """Test that different metric queries use different cache keys (future expansion)"""
        # Currently only /routing/metrics, but could expand to:
        # - metrics:latest (current metrics)
        # - metrics:hourly:{hour} (hourly aggregations)
        # - metrics:daily:{date} (daily aggregations)
        pass  # Reserved for future enhancement


class TestCacheIntegration:
    """Integration tests for end-to-end caching behavior"""

    @pytest.fixture
    def client(self):
        """FastAPI test client"""
        return TestClient(app)

    def test_cache_lifecycle(self, client):
        """Test complete cache lifecycle: miss -> populate -> hit"""
        # This test requires actual Redis to be running
        # It verifies the full flow without mocking

        # First request (cache miss)
        response1 = client.get("/routing/metrics")
        assert response1.status_code == 200
        data1 = response1.json()

        # Second request (should hit cache if implemented)
        response2 = client.get("/routing/metrics")
        assert response2.status_code == 200
        data2 = response2.json()

        # Data should be identical (except timestamp which regenerates on cache miss)
        # Remove timestamp before comparison
        data1_copy = {k: v for k, v in data1.items() if k != 'timestamp'}
        data2_copy = {k: v for k, v in data2.items() if k != 'timestamp'}
        assert data1_copy == data2_copy

    def test_cache_ttl_expiration(self, client):
        """Test that cache expires after TTL (30 seconds)"""
        # This test would require waiting 30+ seconds
        # Skipping for CI/CD speed, but documents expected behavior
        pytest.skip("TTL test requires 30+ second wait")

    def test_concurrent_requests_cache_performance(self, client):
        """Test that concurrent requests benefit from caching and counters are accurate with lock safety"""
        import concurrent.futures
        import time

        # Get baseline stats
        baseline_response = client.get("/metrics-cache/stats")
        assert baseline_response.status_code == 200
        baseline_stats = baseline_response.json()
        baseline_hits = baseline_stats["hits"]
        baseline_misses = baseline_stats["misses"]

        # Populate cache with first request
        first_response = client.get("/routing/metrics")
        assert first_response.status_code == 200

        # Give Redis a moment to set the cache
        time.sleep(0.1)

        # Make 10 concurrent requests (should all hit cache)
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            futures = [executor.submit(client.get, "/routing/metrics") for _ in range(10)]
            responses = [f.result() for f in futures]

        # All should succeed
        assert all(r.status_code == 200 for r in responses), "All concurrent requests should succeed"

        # All should return same data
        data_list = [r.json() for r in responses]

        # Remove timestamps before comparison
        data_list_no_ts = [{k: v for k, v in d.items() if k != 'timestamp'} for d in data_list]

        # Compare all responses to first response
        for data in data_list_no_ts[1:]:
            assert data == data_list_no_ts[0], "All concurrent responses should return same cached data"

        # Verify counters are accurate
        final_response = client.get("/metrics-cache/stats")
        assert final_response.status_code == 200
        final_stats = final_response.json()

        # The key assertion: verify that counters are consistent and no race condition lost increments
        # At least 10 requests should have been successfully tracked (1 miss + at least 9 hits)
        total_tracked = final_stats["hits"] + final_stats["misses"]
        assert total_tracked >= 11, \
            f"Should track at least 11 requests total, got {total_tracked}"

        # Verify hit rate is reasonable (should have some cache hits)
        hit_rate = final_stats["hit_rate_percent"]
        assert hit_rate >= 0, "Hit rate should be non-negative"

        # Most importantly: verify that the lock prevents lost increments
        # by checking that counters increased monotonically (no lost updates)
        assert final_stats["hits"] >= baseline_hits, "Hits should never decrease"
        assert final_stats["misses"] >= baseline_misses, "Misses should never decrease"
